# 2.4 Scheduling

Module covered from 02/20/19 to 02/25/19. 

## Table of contents

- [What is scheduling](#what-is-scheduling)
- [When to make scheduling decisions](#when-to-make-scheduling-decisions)
- [Categories of scheduling algorithms](#categories-of-scheduling-algorithms)
- [Goals of scheduling algorithms](#goals-of-scheduling-algorithms)
- [Scheduling in batch systems](#scheduling-in-batch-systems)
  - [1. First-Come, First-Served](#1-first-come-first-served-fcfs) 
  - [2. Shortest Job First](#2-shortest-job-first)
  - [3. Shortest Remaining Time Next](#3-shortest-remaining-time-next) 
- [Scheduling in interactive systems](#scheduling-in-interactive-systems) 
  - [1. Round robin](#1-round-robin)
  - [2. Process sharing](#2-process-sharing)
  - [3. Priority scheduling](#3-priority-scheduling)
  - [4. Selfish-RR](#4-selfish-rr) 
  - [5. Multilevel queues](#5-multilevel-queues)
  - [6. Multiple queues](#6-multiple-queues)
  - [7. Shortest process next](#-shortest-process-next)
  - [8. Highest penalty ratio next](#8-highest-penalty-ratio-next)
  - [9. Guaranteed scheduling](#9-guaranteed-scheduling)
  - [10. Lottery scheduling](#10-lottery-scheduling)
  - [11. Fair share scheduling](#11-fair-share-scheduling) 
- [Medium-Term Scheduling](#medium-term-scheduling)

## Notes 

### What is scheduling 

- early computing: computer systems were monoprogrammed 
- modern PCs are multiprogrammed 
  - most of the time there's only one active process
  - scheduling not critical (one user)
- scheduling-intensive situations
  - a bunch of users and/or if the demands of the jobs differ (e.g. P1 accepts user requests P2 calculates numbers)
  - batch servers
  - Time sharing machines 
- process behavior
  - *CPU bound (CPU burst)* (computing)
  - *I/O bound (I/O bursts)*: process enters a blocked states waiting for external device to complete work 

### When to make scheduling decisions

- **new process creation**
  - e.g. fork(); scheduling is *desirable* as it takes the new process inot account 
- **when a process exits**
  - e.g. exit(); scheduling is *necessary* because the previous process no longer exists
- **a process blocked** (Running —> Blocked)
  - e.g. read(); scheduling is *necessary* previous processs is blocked 
- **a process unblocked** 
  - e.g. I/O interrupts happen (to let process know that I/O has finished) scheduling is *desirable* as the blocked processs is now in Blocked —> Ready state 
- **process is preempted** (Running —> Ready)
  - scheduling is *necessary* 
  - done by scheduler itself; requires a clock interrupt (every 50-60Hz) to make scheduling possible 
- **Preemptive scheduling**
  - shceudler lets the process run for a maximum amount of time based on policy
  - Running —> Ready without process request 
  - needs a *clock interrupt* to occur at the end of the time interval to give control back to the scheduler 
  - expensive 

- **Nonpreemptive scheduling** 
  - scheduler picks a process, lets it run until: 
    - it blocks (by I/O, waiting for another process)
    - voluntarily releases the CPU
  - If there's no clock, nonpreemptive scheduling is the only available option

### Categories of scheduling algorithms

- **Batch**
  - systems doing accounts receivable, payroll, etc. used in banks, insurance companies, etc.
  - no waiting users 
  - Nonpreemptive, or preemptive w/ long time periods 
    - reduces process switching 
- **Interactive systems**
  - preemption is critical for rapid response time to short requests. 
- **Real time (deadlines)**
  - preemption is not that important 
  - processes operate within their approved time window 
  - critical systems

### Goals of scheduling algorithms

1. fairness 
2. respecting priority
3. efficiency 
4. low turnaround time
5. High throughput
6. low response time 
7. degrade gracefully under load

Note: *low turnaround time*:  every job coming in [submission] spend as little time in the system as possible [termination]

| Non-preemptive | Preemptive                          |
| -------------- | ----------------------------------- |
| FCFS           | Round-robin                         |
| SJF            | Shortest Remaining Time Next (SRTN) |
|                |                                     |
|                |                                     |
|                |                                     |



### Scheduling in batch systems

#### 1. First-Come, First-Served (FCFS)

- Essentially FIFO
- easy to implement 
- processes assigned CPU time in order they request it 
  - single queue for ready processes 
  - a Blocked —> Ready process joins the end of the queue 
- <u>Nonpreemptive</u> (scheduler won't preempt and force running process to ready)
- won't work for a varied workload (what if the first process takes an hour to run but the second takes only seconds?)

#### 2. Shortest Job First

- sort jobs by execution time needed and run the shortest first 
- Aim: **minimize turnaround time**
- jobs' runtime in advance (problematic, if not impossible, in practice)
  - may be able to project runtime given prior runs 
- jobs need to be available simultaneously
- <u>Nonpreemptive</u>
- Provably optimal: proven to have lowest avg. wait time, given runtimes as inputs 
  - Scratch proof (Assume these jobs won't run into blocks): 
    - 4 jobs with runtimes of a, b, c, d
    - first finishes at a, second a + b, third a + b + c, fourth a + b + c + d
    - mean turnaround time is `(4a + 3b + 2c + d) / 4`
    - `MIN(Turnaround Time)` ==> has to satisfy `a < b < c < d`

#### 3. Shortest Remaining Time Next

- Picks job with shortest time to execute next
- <u>Preemptive</u>: the current running process has been proven to have the shortest remaining time left (among the current processes), the only variable that may change the situation is a new process coming in
- need to know runtime in advance 

### Scheduling in interactive systems 

#### 1. Round robin 

- Each process is assigned a CPU running time interval (referred to as <u>quantum</u>)
- If the process uses up quantum
  - CPU preempts at the end of the quantum
- If process is blocked or finished before quantum 
  - CPU switches to the next process 
- Preemptive version of FCFS (FIFO)
- Preemption requires a <u>clock interrupt</u>
- Does not require run times in advance 
- Determining the duration of quantum is critical
  - Quantum too short
    - system is less efficient <== too many process switches (state saving, transfer-of-control, etc.)
  -  Quantum too long
    - system is less responsive ==> poor responses to short interactive requests 

#### 2. Process sharing 

- merge the ready and running; permit all jobs to run at once
- i.e. if there are N jobs in the queue
  - every job runs at a `1/N` speed (compared to its speed if it were running alone)
- Theoretical (in reality one processor runs one process at a time)

#### 3. Priority scheduling 

- Each job is assigned a priority (can be based on factors external to the process)
- Run jobs according to priority (static; dynamic to favor certain processes) 
  - e.g. Shorted jobs first (SJF) is a priority scheduling algorithm
- use RR among processes with the samme priority 
- Can starve processes (if you keep adding higher-p processes, loewr-p processes can be starved)
- **Priority aging**: raise priority to ensure that lower-priority processes get a chance to run 

#### 4. Selfish RR

- Preemptive policy
- **2 queues**
  - active queue
    - Assign CPU time w/ RR
    - processes remain in the queue until termination
  - holding (waiting) queue
    - processes request to be joined to active queue 
    - accepted if priority matches those in the active queue (or if active queue is empty)
- **Priority assignment**
  - In active queue: priority increases at rate `a`
  - In holding queue: priority increases at a rate `b`
  - relationship b/t `a` and `b`
    - a = 0: results in RR (no holding queue)
    - a >= b >= 0: FCFS
    - b > a > 0: *interesting*
    - a > b = 0: RR in batches (active queue gets added only if they are empty)
  - what if a process is blocked?
    - 1) reset the priority to 0 (easiest)
    - 2) keep current priority 
    - 3) ignore block state, continue to increase priority 

#### 5. Multilevel queues

- try to statically get an environment where highest priorities are assigned to shortest jobs
- Goal: reduce average waiting time 
- processes are assigned to a queue and do not move from one queue to another 
  - queues can have independent scheduling policies (e.g. FCFS for background, RR foreground ones)
    - might apply priority aging to prevent background starvation 
  - must have policy among queues
    - e.g. the queue with higher priority can have higher # of cycle

#### 6. Multiple queues

- dynamic behavior (as opposed to static in multilevel queues)
- separate queues with different priority classes
- processes *can* move between queues
  - dynamically separate "batch-like" processes from interactive ones, favoring interactive ones
  - if process is using full quanta (batch-like), lower priority 
  - Otherwise, move it to a higher priority queue (e.g. move up priority when user enters ENTER repeatedly; OS thinks there's IO)
  - suits long proxesses w/ frequent IO
  - priority aging is applied to prevent starvation

#### 7. Shortest process next

- The interactive equivalent for SJF
- Remaining times for each "job" estimated from prior runs
- **remaining time estimation**
  - choose some initial estimate when process starts
  - `new estimate = A * old estimate + (1 - A) * last burst`
    - `last burst` is the actual time used in previous run 
    - `0 < A < 1` determines how quickly old runs are forgotten 
      - older runs may not be applicable now (e.g. a process may be very intensive at first but is less intensive later)

#### 8. Highest penalty ratio next

- Non-preemptive: the decision is not made while the process is running
- for each process, calculate the **penalty ratio r**: `r = T/t`
  - `T`: time in the system
  - `t`: running time of process to date
    - define `t` to be 1 so that the ratio is always defined 
- when an old process is terminated, process with **highest penalty ratio** is run next

#### 9. Guaranteed scheduling

- Guarantee that when `n` processes are running in the system, each should get `1/n` CPU cycles. 
  - Compute the amount of CPU time each process has: `T/n`
  - Keep track of CPU time each process has had since creation
  - Ratio of actual CPU time consumed to CPU time entitled: `t/(T/n) = ? nt/T`
- runs process w/ the lowest ratio until the ratio is above another process's. 

#### 10. Lottery scheduling 

- Use lottery tickets for various system resources i.e. CPU time 
- hold lottery for CPU time several times a second 
  - ...
- processes can share tickets
- if you have ticket, you get CPU time; more tickets, more important processes
- simpler to implement than guaranteed scheduling

#### 11. Fair share scheduling 

- user-oriented, a level up from the previous process-oriented approaches
- prevents users w/ many processes getting more services than users w/ few processes
- each user is allocated a fraction of the CPU

### Medium-Term Scheduling

![image-20190225115338408](/Users/viclee/Library/Application Support/typora-user-images/image-20190225115338408.png)

- Medium-term scheduling is more about memory (swaping in and out from main memory to secondary memory)
- considerations
  - how long since previously suspended
  - how much CPU used
  - how much memory used 
  - external considerations 